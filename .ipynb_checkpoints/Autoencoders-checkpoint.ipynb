{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by [Samuel Adekunle](mailto:sja119@ic.ac.uk)\n",
    "\n",
    "For [AI Core](http://www.theaicore.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Autoencoders\n",
    "\n",
    "An [Autoencoder](https://en.wikipedia.org/wiki/Autoencoder) is a type of neural network that is used to learn efficient data encodings in an unsupervised manner. What this means is autoencoders learn to recognise the most important features of the data they are fed, and reject the less important ones (i.e. noise). In doing so, they can reduce the dimensionality of the number of features needed to represent the same data. This is the data encoding part of an autoencoder.\n",
    "\n",
    "![image](img/autoencoder.png)\n",
    "\n",
    "In order to learn which features are most important, an autoencoder tries to reconstruct the same data from the reduced set of instructions. This is why it's called unsupervised learning because no additional labels are needed. The input is the ground truth that the output is compared. The Autoencoder typically trains on reconstruction losses such as the Mean-Square Error as it's trying to perfectly reproduce the data.\n",
    "\n",
    "\n",
    "Putting it all together, an autoencoder can be defined as consisting of two parts, the encoder and the decoder, which can be defined mathematically as:\n",
    "\n",
    "![image](img/transitions.png)\n",
    "\n",
    "![image](img/encoder_decoder.png)\n",
    "\n",
    "![image](img/hidden_state.png)\n",
    "\n",
    "## Uses of Autoencoders\n",
    "\n",
    " - Denoising Data (e.g. Images, Audio)\n",
    " - Anomaly Detection\n",
    " - Information Retrival (Dimensionality Reduction)\n",
    " - Object Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Autoencoder\n",
    "\n",
    "This basic architechture will take the input and try to reproduce it at the output.\n",
    "\n",
    "![image](img/feed.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All requirements for this notebook\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 5000\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using popular MNIST dataset\n",
    "train_data = torchvision.datasets.MNIST(root='MNIST-data',\n",
    "                                        transform=torchvision.transforms.ToTensor(),\n",
    "                                        train=True,\n",
    "                                        download=True\n",
    "                                        )\n",
    "test_data = torchvision.datasets.MNIST(root='MNIST-data',\n",
    "                                       transform=torchvision.transforms.ToTensor(),\n",
    "                                       train=False\n",
    "                                       )\n",
    "\n",
    "print(f\"Shape of MNIST Training Dataset: {train_data.data.shape}\")\n",
    "print(f\"Shape of MNIST Testing Dataset: {test_data.data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_helper(image):\n",
    "    image = image.view(28, 28)\n",
    "    plt.imshow(image.cpu().detach())\n",
    "    plt.show()\n",
    "    print(\"Max Element: \", rdm_img.max())\n",
    "    print(\"Min Element: \", rdm_img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are we working with and what will we be doing\n",
    "rdm_img = train_data.data[np.random.randint(\n",
    "    0, 100)] / 255.0  # get a random example\n",
    "show_image_helper(rdm_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FURTHER SPLIT THE TRAINING INTO TRAINING AND VALIDATION\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [\n",
    "                                                     50000, 10000])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# MAKE TRAINING DATALOADER\n",
    "train_loader = torch.utils.data.DataLoader(  # create a data loader\n",
    "    train_data,  # what dataset should it sample from?\n",
    "    shuffle=True,  # should it shuffle the examples?\n",
    "    batch_size=BATCH_SIZE  # how large should the batches that it samples be?\n",
    ")\n",
    "\n",
    "# MAKE VALIDATION DATALOADER\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# MAKE TEST DATALOADER\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, code_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, code_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(code_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs=10, learning_rate=0.01):\n",
    "    global EPOCHS\n",
    "    model.train()\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        EPOCHS += 1\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for org_img, _ in train_loader:\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            org_img = org_img.double().view(-1, 784).to(device) / 255.0\n",
    "            gen_img = model(org_img).double()\n",
    "\n",
    "            loss = criterion(gen_img, org_img)\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "\n",
    "            loss.backward()  # backpropagate\n",
    "            optimiser.step()\n",
    "\n",
    "        average_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {EPOCHS}:\\tScore: {1/average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 0\n",
    "INPUT_SIZE = 28*28\n",
    "HIDDEN_SIZE = 128\n",
    "CODE_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "autoencoder = AutoEncoder(\n",
    "    INPUT_SIZE, HIDDEN_SIZE, CODE_SIZE).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "train(autoencoder, num_epochs, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "#     criterion = torch.nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for val_img, _ in val_loader:\n",
    "        val_img = val_img.double().view(-1, 784).to(device) / 255.0\n",
    "        gen_img = model(val_img).double()\n",
    "        loss = criterion(gen_img, val_img)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "    average_loss = total_loss / num_batches\n",
    "    return 1/average_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = validate(autoencoder)\n",
    "print(\"Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "#   criterion = torch.nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    stored_images = []\n",
    "    for test_img, _ in test_loader:\n",
    "        test_img = test_img.double().view(-1, 784).to(device) / 255.0\n",
    "        gen_img = model(test_img)\n",
    "        loss = criterion(gen_img.double(), test_img).item()\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        if np.random.random() > 0.75:\n",
    "            stored_images.append(\n",
    "                (test_img[0].clone().detach(), gen_img[0].clone().detach()))\n",
    "\n",
    "    score = average_loss = total_loss / num_batches\n",
    "    print(f\"Score: {1/score}\\n\")\n",
    "\n",
    "    for original, generated in stored_images:\n",
    "        print(\"Original: \")\n",
    "        show_image_helper(original)\n",
    "        print(\"Generated: \")\n",
    "        show_image_helper(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application - Denoising an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds some noise to the input before passing it in to the autoencoder network but uses the original image as the ground truth, effectively training the autoencoder network to reject the noise and learn the data encodings that represent the data beneath the noise. The only difference is in the training loop\n",
    "\n",
    "![image](img/denoising.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(clean_image, noise_factor=0.0):\n",
    "    random_noise = torch.randn_like(clean_image)\n",
    "    random_noise /= random_noise.max() # between -1 and 1\n",
    "    noisy_image = clean_image + (noise_factor * random_noise)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_noise(model, num_epochs=10, learning_rate=0.01, noise_factor=0.0):\n",
    "    global EPOCHS\n",
    "    model.train()\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        EPOCHS += 1\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for org_img, _ in train_loader:\n",
    "            optimiser.zero_grad()\n",
    "            org_img = org_img.double().view(-1, 784).to(device) / 255.0\n",
    "            noisy_img = add_noise(org_img, noise_factor)\n",
    "            gen_img = model(noisy_img).double()\n",
    "\n",
    "            loss = criterion(gen_img, org_img)\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "\n",
    "            loss.backward()  # backpropagate\n",
    "            optimiser.step()\n",
    "\n",
    "        average_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {EPOCHS}:\\tScore: {1/average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 0\n",
    "INPUT_SIZE = 28*28\n",
    "HIDDEN_SIZE = 128\n",
    "CODE_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "NOISE_FACTOR = 0.001\n",
    "\n",
    "denoise_autoencoder = AutoEncoder(\n",
    "    INPUT_SIZE, HIDDEN_SIZE, CODE_SIZE).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "train_noise(denoise_autoencoder, num_epochs, LEARNING_RATE, NOISE_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_noise(model, noise_factor=NOISE_FACTOR):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "#     criterion = torch.nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for val_img, _ in val_loader:\n",
    "        val_img = val_img.double().view(-1, 784).to(device) / 255.0\n",
    "        gen_img = model(add_noise(val_img, noise_factor)).double()\n",
    "\n",
    "        loss = criterion(gen_img, val_img)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "    average_loss = total_loss / num_batches\n",
    "    return 1/average_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = validate_noise(denoise_autoencoder)\n",
    "print(\"Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_noise(model, noise_factor=NOISE_FACTOR):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "#   criterion = torch.nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    stored_images = []\n",
    "    for test_img, _ in test_loader:\n",
    "        test_img = test_img.double().view(-1, 784).to(device) / 255.0\n",
    "        noisy_img = add_noise(test_img, noise_factor)\n",
    "        gen_img = model(noisy_img).double()\n",
    "        \n",
    "        loss = criterion(gen_img, test_img)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        if np.random.random() > 0.75:\n",
    "            stored_images.append((test_img[0].clone().detach(\n",
    "            ), noisy_img[0].clone().detach(), gen_img[0].clone().detach()))\n",
    "\n",
    "    score = average_loss = total_loss / num_batches\n",
    "    print(f\"Score: {1/score}\\n\")\n",
    "\n",
    "    for original, noisy, generated in stored_images:\n",
    "        print(\"Original: \")\n",
    "        show_image_helper(original)\n",
    "        print(\"Noisy: \")\n",
    "        show_image_helper(noisy)\n",
    "        print(\"Generated: \")\n",
    "        show_image_helper(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_noise(denoise_autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    " - [Wikipedia](https://en.wikipedia.org/wiki/Autoencoder)\n",
    " - [Jeremy Jordan](https://www.jeremyjordan.me/autoencoders/)\n",
    " - [TowardsDataScience](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
