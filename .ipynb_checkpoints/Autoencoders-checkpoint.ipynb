{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All requirements for this notebook\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 5000\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will be using popular MNIST dataset\n",
    "train_data = torchvision.datasets.MNIST(root='MNIST-data', \n",
    "                                        transform=torchvision.transforms.ToTensor(),\n",
    "                                        train=True,\n",
    "                                        download=True\n",
    "                                       )\n",
    "test_data = torchvision.datasets.MNIST(root='MNIST-data', \n",
    "                                        transform=torchvision.transforms.ToTensor(),\n",
    "                                        train=False\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_helper(image):\n",
    "    image = image.view(28, 28)\n",
    "    plt.imshow(image.cpu().detach(), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(\"Max Element: \", rdm_img.max())\n",
    "    print(\"Min Element: \", rdm_img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of MNIST Dataset: torch.Size([60000, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Element:  tensor(1.)\n",
      "Min Element:  tensor(0.)\n",
      "Shape of Image: torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "##What are we working with and what will we be doing\n",
    "print(f\"Shape of MNIST Dataset: {train_data.data.shape}\")\n",
    "rdm_img = train_data.data[np.random.randint(0,100)] / 255.0# get a random example\n",
    "show_image_helper(rdm_img)\n",
    "print(f\"Shape of Image: {rdm_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FURTHER SPLIT THE TRAINING INTO TRAINING AND VALIDATION\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [50000, 10000])\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# MAKE TRAINING DATALOADER\n",
    "train_loader = torch.utils.data.DataLoader( # create a data loader\n",
    "    train_data, # what dataset should it sample from?\n",
    "    shuffle=True, # should it shuffle the examples?\n",
    "    batch_size=BATCH_SIZE # how large should the batches that it samples be?\n",
    ")\n",
    "\n",
    "# MAKE VALIDATION DATALOADER\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# MAKE TEST DATALOADER\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], input_dim)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(self.hidden_dims) -1):\n",
    "            self.hidden_layers.append(nn.Linear(self.hidden_dims[i], self.hidden_dims[i+1]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = hidden_layer(x)\n",
    "            x = torch.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=10, learning_rate=0.001):\n",
    "    model.train()\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            optimiser.zero_grad() ##zero out previous gradient map\n",
    "\n",
    "            org_img, _ = batch ##don't need the label for Autoencoder training\n",
    "            org_img = org_img.view(-1, 784).to(device) / 255.0\n",
    "            org_img = org_img.double()\n",
    "            gen_img = model(org_img)\n",
    "            loss = criterion(gen_img.double(), org_img)\n",
    "#             print(f\"Epoch: {epoch}\\tBatch: {idx}\\tLoss: {loss}\")\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "            loss.backward() ## backpropagate\n",
    "            optimiser.step()\n",
    "        average_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch}:\\tScore: {1/average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 28*28\n",
    "HIDDEN_DIM = [128, 32, 128]\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "my_autoencoder = AutoEncoder(INPUT_DIM, HIDDEN_DIM).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(my_autoencoder, EPOCHS, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, display_image=True):\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for val_img, _ in val_loader:\n",
    "        val_img = val_img.to(device).double()\n",
    "        val_img = val_img.view(-1, 784) / 255.0\n",
    "        gen_img = model(val_img)\n",
    "        if display_image:\n",
    "            img_idx = np.random.randint(BATCH_SIZE)\n",
    "            print(\"Generated Image\")\n",
    "            show_image_helper(gen_img[img_idx])\n",
    "            print(\"Clean Image\")\n",
    "            show_image_helper(val_img[img_idx])\n",
    "            print(1/criterion(gen_img.double(), val_img).item())\n",
    "            return\n",
    "        loss = criterion(gen_img.double(), val_img).item()\n",
    "        total_loss += loss\n",
    "        num_batches +=1\n",
    "    average_loss = total_loss / num_batches\n",
    "    return 1/average_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Element:  tensor(1.)\n",
      "Min Element:  tensor(0.)\n",
      "Clean Image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Element:  tensor(1.)\n",
      "Min Element:  tensor(0.)\n",
      "277.58220584483814\n"
     ]
    }
   ],
   "source": [
    "DISPLAY_IMAGES = True\n",
    "score = validate(my_autoencoder, DISPLAY_IMAGES)\n",
    "if not DISPLAY_IMAGES: print(\"Score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application - Denoising an Image (CovNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(clean_image, noise_factor):\n",
    "    clean_image = clean_image.to(device)\n",
    "    noisy_image = clean_image + noise_factor * torch.as_tensor(np.random.standard_normal(clean_image.shape), device=device)\n",
    "    noisy_image = torch.clamp(noisy_image, 0.0, 1.0).double()\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderCNN(nn.Module):\n",
    "    def __init__(self, input_dim, filter_dims, kernel_sizes, stride = 2):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Conv2d(1, 32, 5, 2)\n",
    "        self.mid_input_later = nn.Conv2d(32, 64, 5, 2)\n",
    "        self.mid_output_layer = nn.Conv2d(64, 32, 5, 2)\n",
    "        self.output_layer = nn.Conv2d(32, 1, 5, 2)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = hidden_layer(x)\n",
    "            x = torch.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
