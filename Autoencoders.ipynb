{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by [Samuel Adekunle](mailto:sja119@ic.ac.uk)\n",
    "\n",
    "For [AI Core](http://www.theaicore.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uses of Autoencoders\n",
    "\n",
    "### Image/Audio Denoising\n",
    "\n",
    "Autoencoders are very good at removing noise from images and generating a much clearer picture than the original. Later we will see how this can easily be implemented.\n",
    "\n",
    "![image](img/denoising_example.png)\n",
    "\n",
    "### Image Generation\n",
    "\n",
    "An alternative to GANs are a variant of autoencoders known as [Variational Autoencoders](https://en.wikipedia.org/wiki/Autoencoder#Variational_autoencoder_(VAE)). There's a lot of complicated math involved but in summarhy, te input is an image, and the variational autoencoder learns it's distribution and can generate similar images.\n",
    "\n",
    "![faces generated with a vae](img/faces.png)\n",
    "\n",
    "*Faces generated with a Variational Autoencoder Model (source: [Wojciech Mormul on Github](https://github.com/WojciechMormul/vae))*\n",
    "\n",
    "### Image Inpainting and Photo Restoration\n",
    "\n",
    "![context encoders](img/inpainting.jpg)\n",
    "\n",
    "*Faces generated with a Variational Autoencoder Model (source: [Context Encoders: Feature Learning by Inpainting](https://people.eecs.berkeley.edu/~pathak/context_encoder/))*\n",
    "\n",
    "### Other Uses:\n",
    " - Anomaly Detection and Facial Recogniton\n",
    " - Feature Extraction and Data Compression\n",
    " - Language Translation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Basic Architecture\n",
    "\n",
    "An [Autoencoder](https://en.wikipedia.org/wiki/Autoencoder) is a neural network architecture that learns efficient data encodings in an unsupervised manner. What this means is autoencoders learn to recognise the most important features of the data they are fed, and reject the less important ones (i.e. noise). In doing so, they can reduce the dimensionality of the number of features needed to represent the same data. It does this in two steps:\n",
    "\n",
    " - Data Encoding: The input data is forced through a bottleneck and transfomed into a feature space, which is typically much smaller than the input space. The encoder is trained so that this feature space represents the most important features in the input space that are needed to reconstruct the data. Note: If the feature space is not smaller than the input space, then the encoder might just learn the identity function.\n",
    " \n",
    " - Data Decoding: After the input data has been reduced to some feature space, the autoencoder tries to reconstruct the original data from the reduced feature space. This is why an autoencoder is often said to undergo **unsupervised training**. The original input data is what is compared against the output of the network and used to train it. Typically in training the autoencoder, the network tries to minimize a reconstruction loss, such as the Mean Squared Error between the input and the output.\n",
    "\n",
    "![image](img/transitions.png)\n",
    "\n",
    "*Mathematical Definition of an Autoencoder (source: [Wikipedia](https://en.wikipedia.org/wiki/Autoencoder))*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Autoencoder\n",
    "\n",
    "This basic architechture will take the input and try to reproduce it at the output.\n",
    "\n",
    "![feed_foward_autoencoder](img/encoder_decoder.png)\n",
    "\n",
    "*Basic Reconstruction Autoencoder Architecture (source: [Jeremy Jordan](https://www.jeremyjordan.me/autoencoders/))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt\n",
    "# Run only once to install requirements for notebook then restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All requirements for this notebook\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 5000\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using popular MNIST dataset\n",
    "train_data = torchvision.datasets.MNIST(root='MNIST-data',\n",
    "                                        transform=torchvision.transforms.ToTensor(),\n",
    "                                        train=True,\n",
    "                                        download=True\n",
    "                                        )\n",
    "test_data = torchvision.datasets.MNIST(root='MNIST-data',\n",
    "                                       transform=torchvision.transforms.ToTensor(),\n",
    "                                       train=False\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of MNIST Training Dataset: {train_data.data.shape}\")\n",
    "print(f\"Shape of MNIST Testing Dataset: {test_data.data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_helper(image):\n",
    "    image = image.view(28, 28)\n",
    "    plt.imshow(image.cpu().detach())\n",
    "    plt.show()\n",
    "    print(\"Max Element: \", rdm_img.max())\n",
    "    print(\"Min Element: \", rdm_img.min())\n",
    "    \n",
    "def show_losses_helper(losses):\n",
    "    plt.plot(losses[1:])\n",
    "    plt.ylabel(\"Losses\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title(\"Autoencoder Losses\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are we working with and what will we be doing\n",
    "rdm_img = train_data.data[np.random.randint(\n",
    "    0, 100)] / 255.0  # get a random example\n",
    "show_image_helper(rdm_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FURTHER SPLIT THE TRAINING INTO TRAINING AND VALIDATION\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [\n",
    "                                                     50000, 10000])\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# MAKE TRAINING DATALOADER\n",
    "train_loader = torch.utils.data.DataLoader(  # create a data loader\n",
    "    train_data,  # what dataset should it sample from?\n",
    "    shuffle=True,  # should it shuffle the examples?\n",
    "    batch_size=BATCH_SIZE  # how large should the batches that it samples be?\n",
    ")\n",
    "\n",
    "# MAKE VALIDATION DATALOADER\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# MAKE TEST DATALOADER\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, code_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "        # TODO: implement encoder\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "        # TODO: implement decoder\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs=10, learning_rate=0.01):\n",
    "    global EPOCHS\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    \n",
    "    ## add optimiser and criterion\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        EPOCHS += 1\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for org_img, _ in train_loader:\n",
    "            optimiser.zero_grad() # reset gradients\n",
    "\n",
    "            ## transform the image to a suitable input for the model\n",
    "            \n",
    "            gen_img = model(org_img).double()\n",
    "\n",
    "            loss = criterion(gen_img, org_img)\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "\n",
    "            loss.backward()  # backpropagate\n",
    "            optimiser.step()\n",
    "\n",
    "        # calculate average loss\n",
    "        losses.append(average_loss)\n",
    "        print(f\"Epoch {EPOCHS}:\\tScore: {1/average_loss}\")\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 0\n",
    "INPUT_SIZE = 28*28\n",
    "HIDDEN_SIZE = 128\n",
    "CODE_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "autoencoder = AutoEncoder(\n",
    "    INPUT_SIZE, HIDDEN_SIZE, CODE_SIZE).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "losses = train(autoencoder, num_epochs, LEARNING_RATE)\n",
    "show_losses_helper(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "#     criterion = torch.nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for val_img, _ in val_loader:\n",
    "        val_img = val_img.double().view(-1, 784).to(device) / 255.0\n",
    "        gen_img = model(val_img).double()\n",
    "        loss = criterion(gen_img, val_img)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "    average_loss = total_loss / num_batches\n",
    "    return 1/average_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = validate(autoencoder)\n",
    "print(\"Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "#   criterion = torch.nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    stored_images = []\n",
    "    for test_img, _ in test_loader:\n",
    "        test_img = test_img.double().view(-1, 784).to(device) / 255.0\n",
    "        gen_img = model(test_img)\n",
    "        loss = criterion(gen_img.double(), test_img).item()\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        if np.random.random() > 0.80:\n",
    "            stored_images.append(\n",
    "                (test_img[0].clone().detach(), gen_img[0].clone().detach()))\n",
    "\n",
    "    score = average_loss = total_loss / num_batches\n",
    "    print(f\"Score: {1/score}\\n\")\n",
    "\n",
    "    for original, generated in stored_images:\n",
    "        print(\"Original: \")\n",
    "        show_image_helper(original)\n",
    "        print(\"Generated: \")\n",
    "        show_image_helper(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing MSE to BCE\n",
    "\n",
    "Generally, when dealing with Autoencoders or similar problems, we train using a loss like MSE which would compare the generated image and the original one, pixel by pixel in order to calculate the error. \n",
    "\n",
    "This is fine most of the time, but would not have been optimal in our case. Our images have values varying only between 0 and 1 and most of them are zero anyways, so this means the mean square error will always be very low, which will not allow our model to train effectively.\n",
    "\n",
    "![mean_square_error_loss](img/mse_losses.png)\n",
    "\n",
    "The alternative we used was the Binary Cross Entropy Error. Typically this is used for categorical problems, but in our case we are trying to distinguish between a high (1.0) and a low(0.0) so the cross entropy loss can still be used. Because our numbers are between 0 and 1 we use a binary cross entropy.\n",
    "\n",
    "![binary_cross_entropy_loss](img/bce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application - Denoising an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds some noise to the input before passing it in to the autoencoder network but uses the original image as the ground truth, effectively training the autoencoder network to reject the noise and learn the data encodings that represent the data beneath the noise. The only difference is in the training loop\n",
    "\n",
    "![denoising_autoencoder_architecture](img/denoising.png)\n",
    "\n",
    "*Denoising Autoencoder Architecture (source: [Jeremy Jordan](https://www.jeremyjordan.me/autoencoders/))*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(clean_image, noise_factor=0.0):\n",
    "    random_noise = torch.randn_like(clean_image)\n",
    "    random_noise /= random_noise.max() # between -1 and 1\n",
    "    noisy_image = clean_image + (noise_factor * random_noise)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_noise(model, num_epochs=10, learning_rate=0.01, noise_factor=0.0):\n",
    "    global EPOCHS\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    # add optimiser and criterion\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        EPOCHS += 1\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for org_img, _ in train_loader:\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            org_img = #transform original image\n",
    "            noisy_img = #add noise to image\n",
    "            \n",
    "            gen_img = model(noisy_img).double()\n",
    "\n",
    "            loss = criterion(gen_img, org_img)\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "\n",
    "            loss.backward()  # backpropagate\n",
    "            optimiser.step()\n",
    "\n",
    "        average_loss = #calculate average losses\n",
    "        losses.append(average_loss)\n",
    "        print(f\"Epoch {EPOCHS}:\\tScore: {1/average_loss}\")\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 0\n",
    "INPUT_SIZE = 28*28\n",
    "HIDDEN_SIZE = 128\n",
    "CODE_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "NOISE_FACTOR = 0.001\n",
    "\n",
    "denoise_autoencoder = AutoEncoder(\n",
    "    INPUT_SIZE, HIDDEN_SIZE, CODE_SIZE).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "losses = train_noise(denoise_autoencoder, num_epochs, LEARNING_RATE, NOISE_FACTOR)\n",
    "show_losses_helper(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_noise(model, noise_factor=NOISE_FACTOR):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "#     criterion = torch.nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for val_img, _ in val_loader:\n",
    "        val_img = val_img.double().view(-1, 784).to(device) / 255.0\n",
    "        gen_img = model(add_noise(val_img, noise_factor)).double()\n",
    "\n",
    "        loss = criterion(gen_img, val_img)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "    average_loss = total_loss / num_batches\n",
    "    return 1/average_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = validate_noise(denoise_autoencoder)\n",
    "print(\"Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_noise(model, noise_factor=NOISE_FACTOR):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "#   criterion = torch.nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    stored_images = []\n",
    "    for test_img, _ in test_loader:\n",
    "        test_img = test_img.double().view(-1, 784).to(device) / 255.0\n",
    "        noisy_img = add_noise(test_img, noise_factor)\n",
    "        gen_img = model(noisy_img).double()\n",
    "        \n",
    "        loss = criterion(gen_img, test_img)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        if np.random.random() > 0.80:\n",
    "            stored_images.append((test_img[0].clone().detach(\n",
    "            ), noisy_img[0].clone().detach(), gen_img[0].clone().detach()))\n",
    "\n",
    "    score = average_loss = total_loss / num_batches\n",
    "    print(f\"Score: {1/score}\\n\")\n",
    "\n",
    "    for original, noisy, generated in stored_images:\n",
    "        print(\"Original: \")\n",
    "        show_image_helper(original)\n",
    "        print(\"Noisy: \")\n",
    "        show_image_helper(noisy)\n",
    "        print(\"Generated: \")\n",
    "        show_image_helper(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_noise(denoise_autoencoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
